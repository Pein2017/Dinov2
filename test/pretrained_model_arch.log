2024-11-21 01:14:36,062 Model state_dict:
cls_token: torch.Size([1, 1, 768])
pos_embed: torch.Size([1, 1370, 768])
mask_token: torch.Size([1, 768])
patch_embed.proj.weight: torch.Size([768, 3, 14, 14])
patch_embed.proj.bias: torch.Size([768])
blocks.0.norm1.weight: torch.Size([768])
blocks.0.norm1.bias: torch.Size([768])
blocks.0.attn.qkv.weight: torch.Size([2304, 768])
blocks.0.attn.qkv.bias: torch.Size([2304])
blocks.0.attn.proj.weight: torch.Size([768, 768])
blocks.0.attn.proj.bias: torch.Size([768])
blocks.0.ls1.gamma: torch.Size([768])
blocks.0.norm2.weight: torch.Size([768])
blocks.0.norm2.bias: torch.Size([768])
blocks.0.mlp.fc1.weight: torch.Size([3072, 768])
blocks.0.mlp.fc1.bias: torch.Size([3072])
blocks.0.mlp.fc2.weight: torch.Size([768, 3072])
blocks.0.mlp.fc2.bias: torch.Size([768])
blocks.0.ls2.gamma: torch.Size([768])
blocks.1.norm1.weight: torch.Size([768])
blocks.1.norm1.bias: torch.Size([768])
blocks.1.attn.qkv.weight: torch.Size([2304, 768])
blocks.1.attn.qkv.bias: torch.Size([2304])
blocks.1.attn.proj.weight: torch.Size([768, 768])
blocks.1.attn.proj.bias: torch.Size([768])
blocks.1.ls1.gamma: torch.Size([768])
blocks.1.norm2.weight: torch.Size([768])
blocks.1.norm2.bias: torch.Size([768])
blocks.1.mlp.fc1.weight: torch.Size([3072, 768])
blocks.1.mlp.fc1.bias: torch.Size([3072])
blocks.1.mlp.fc2.weight: torch.Size([768, 3072])
blocks.1.mlp.fc2.bias: torch.Size([768])
blocks.1.ls2.gamma: torch.Size([768])
blocks.2.norm1.weight: torch.Size([768])
blocks.2.norm1.bias: torch.Size([768])
blocks.2.attn.qkv.weight: torch.Size([2304, 768])
blocks.2.attn.qkv.bias: torch.Size([2304])
blocks.2.attn.proj.weight: torch.Size([768, 768])
blocks.2.attn.proj.bias: torch.Size([768])
blocks.2.ls1.gamma: torch.Size([768])
blocks.2.norm2.weight: torch.Size([768])
blocks.2.norm2.bias: torch.Size([768])
blocks.2.mlp.fc1.weight: torch.Size([3072, 768])
blocks.2.mlp.fc1.bias: torch.Size([3072])
blocks.2.mlp.fc2.weight: torch.Size([768, 3072])
blocks.2.mlp.fc2.bias: torch.Size([768])
blocks.2.ls2.gamma: torch.Size([768])
blocks.3.norm1.weight: torch.Size([768])
blocks.3.norm1.bias: torch.Size([768])
blocks.3.attn.qkv.weight: torch.Size([2304, 768])
blocks.3.attn.qkv.bias: torch.Size([2304])
blocks.3.attn.proj.weight: torch.Size([768, 768])
blocks.3.attn.proj.bias: torch.Size([768])
blocks.3.ls1.gamma: torch.Size([768])
blocks.3.norm2.weight: torch.Size([768])
blocks.3.norm2.bias: torch.Size([768])
blocks.3.mlp.fc1.weight: torch.Size([3072, 768])
blocks.3.mlp.fc1.bias: torch.Size([3072])
blocks.3.mlp.fc2.weight: torch.Size([768, 3072])
blocks.3.mlp.fc2.bias: torch.Size([768])
blocks.3.ls2.gamma: torch.Size([768])
blocks.4.norm1.weight: torch.Size([768])
blocks.4.norm1.bias: torch.Size([768])
blocks.4.attn.qkv.weight: torch.Size([2304, 768])
blocks.4.attn.qkv.bias: torch.Size([2304])
blocks.4.attn.proj.weight: torch.Size([768, 768])
blocks.4.attn.proj.bias: torch.Size([768])
blocks.4.ls1.gamma: torch.Size([768])
blocks.4.norm2.weight: torch.Size([768])
blocks.4.norm2.bias: torch.Size([768])
blocks.4.mlp.fc1.weight: torch.Size([3072, 768])
blocks.4.mlp.fc1.bias: torch.Size([3072])
blocks.4.mlp.fc2.weight: torch.Size([768, 3072])
blocks.4.mlp.fc2.bias: torch.Size([768])
blocks.4.ls2.gamma: torch.Size([768])
blocks.5.norm1.weight: torch.Size([768])
blocks.5.norm1.bias: torch.Size([768])
blocks.5.attn.qkv.weight: torch.Size([2304, 768])
blocks.5.attn.qkv.bias: torch.Size([2304])
blocks.5.attn.proj.weight: torch.Size([768, 768])
blocks.5.attn.proj.bias: torch.Size([768])
blocks.5.ls1.gamma: torch.Size([768])
blocks.5.norm2.weight: torch.Size([768])
blocks.5.norm2.bias: torch.Size([768])
blocks.5.mlp.fc1.weight: torch.Size([3072, 768])
blocks.5.mlp.fc1.bias: torch.Size([3072])
blocks.5.mlp.fc2.weight: torch.Size([768, 3072])
blocks.5.mlp.fc2.bias: torch.Size([768])
blocks.5.ls2.gamma: torch.Size([768])
blocks.6.norm1.weight: torch.Size([768])
blocks.6.norm1.bias: torch.Size([768])
blocks.6.attn.qkv.weight: torch.Size([2304, 768])
blocks.6.attn.qkv.bias: torch.Size([2304])
blocks.6.attn.proj.weight: torch.Size([768, 768])
blocks.6.attn.proj.bias: torch.Size([768])
blocks.6.ls1.gamma: torch.Size([768])
blocks.6.norm2.weight: torch.Size([768])
blocks.6.norm2.bias: torch.Size([768])
blocks.6.mlp.fc1.weight: torch.Size([3072, 768])
blocks.6.mlp.fc1.bias: torch.Size([3072])
blocks.6.mlp.fc2.weight: torch.Size([768, 3072])
blocks.6.mlp.fc2.bias: torch.Size([768])
blocks.6.ls2.gamma: torch.Size([768])
blocks.7.norm1.weight: torch.Size([768])
blocks.7.norm1.bias: torch.Size([768])
blocks.7.attn.qkv.weight: torch.Size([2304, 768])
blocks.7.attn.qkv.bias: torch.Size([2304])
blocks.7.attn.proj.weight: torch.Size([768, 768])
blocks.7.attn.proj.bias: torch.Size([768])
blocks.7.ls1.gamma: torch.Size([768])
blocks.7.norm2.weight: torch.Size([768])
blocks.7.norm2.bias: torch.Size([768])
blocks.7.mlp.fc1.weight: torch.Size([3072, 768])
blocks.7.mlp.fc1.bias: torch.Size([3072])
blocks.7.mlp.fc2.weight: torch.Size([768, 3072])
blocks.7.mlp.fc2.bias: torch.Size([768])
blocks.7.ls2.gamma: torch.Size([768])
blocks.8.norm1.weight: torch.Size([768])
blocks.8.norm1.bias: torch.Size([768])
blocks.8.attn.qkv.weight: torch.Size([2304, 768])
blocks.8.attn.qkv.bias: torch.Size([2304])
blocks.8.attn.proj.weight: torch.Size([768, 768])
blocks.8.attn.proj.bias: torch.Size([768])
blocks.8.ls1.gamma: torch.Size([768])
blocks.8.norm2.weight: torch.Size([768])
blocks.8.norm2.bias: torch.Size([768])
blocks.8.mlp.fc1.weight: torch.Size([3072, 768])
blocks.8.mlp.fc1.bias: torch.Size([3072])
blocks.8.mlp.fc2.weight: torch.Size([768, 3072])
blocks.8.mlp.fc2.bias: torch.Size([768])
blocks.8.ls2.gamma: torch.Size([768])
blocks.9.norm1.weight: torch.Size([768])
blocks.9.norm1.bias: torch.Size([768])
blocks.9.attn.qkv.weight: torch.Size([2304, 768])
blocks.9.attn.qkv.bias: torch.Size([2304])
blocks.9.attn.proj.weight: torch.Size([768, 768])
blocks.9.attn.proj.bias: torch.Size([768])
blocks.9.ls1.gamma: torch.Size([768])
blocks.9.norm2.weight: torch.Size([768])
blocks.9.norm2.bias: torch.Size([768])
blocks.9.mlp.fc1.weight: torch.Size([3072, 768])
blocks.9.mlp.fc1.bias: torch.Size([3072])
blocks.9.mlp.fc2.weight: torch.Size([768, 3072])
blocks.9.mlp.fc2.bias: torch.Size([768])
blocks.9.ls2.gamma: torch.Size([768])
blocks.10.norm1.weight: torch.Size([768])
blocks.10.norm1.bias: torch.Size([768])
blocks.10.attn.qkv.weight: torch.Size([2304, 768])
blocks.10.attn.qkv.bias: torch.Size([2304])
blocks.10.attn.proj.weight: torch.Size([768, 768])
blocks.10.attn.proj.bias: torch.Size([768])
blocks.10.ls1.gamma: torch.Size([768])
blocks.10.norm2.weight: torch.Size([768])
blocks.10.norm2.bias: torch.Size([768])
blocks.10.mlp.fc1.weight: torch.Size([3072, 768])
blocks.10.mlp.fc1.bias: torch.Size([3072])
blocks.10.mlp.fc2.weight: torch.Size([768, 3072])
blocks.10.mlp.fc2.bias: torch.Size([768])
blocks.10.ls2.gamma: torch.Size([768])
blocks.11.norm1.weight: torch.Size([768])
blocks.11.norm1.bias: torch.Size([768])
blocks.11.attn.qkv.weight: torch.Size([2304, 768])
blocks.11.attn.qkv.bias: torch.Size([2304])
blocks.11.attn.proj.weight: torch.Size([768, 768])
blocks.11.attn.proj.bias: torch.Size([768])
blocks.11.ls1.gamma: torch.Size([768])
blocks.11.norm2.weight: torch.Size([768])
blocks.11.norm2.bias: torch.Size([768])
blocks.11.mlp.fc1.weight: torch.Size([3072, 768])
blocks.11.mlp.fc1.bias: torch.Size([3072])
blocks.11.mlp.fc2.weight: torch.Size([768, 3072])
blocks.11.mlp.fc2.bias: torch.Size([768])
blocks.11.ls2.gamma: torch.Size([768])
norm.weight: torch.Size([768])
norm.bias: torch.Size([768])
2024-11-21 01:14:36,062 torch.Size([1, 768])
2024-11-21 01:14:36,063 DinoVisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))
    (norm): Identity()
  )
  (blocks): ModuleList(
    (0-11): 12 x NestedTensorBlock(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): MemEffAttention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): LayerScale()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (ls2): LayerScale()
      (drop_path2): Identity()
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (head): Identity()
)
2024-11-21 01:34:03,324 Model state_dict:
cls_token: torch.Size([1, 1, 768])
pos_embed: torch.Size([1, 1370, 768])
mask_token: torch.Size([1, 768])
patch_embed.proj.weight: torch.Size([768, 3, 14, 14])
patch_embed.proj.bias: torch.Size([768])
blocks.0.norm1.weight: torch.Size([768])
blocks.0.norm1.bias: torch.Size([768])
blocks.0.attn.qkv.weight: torch.Size([2304, 768])
blocks.0.attn.qkv.bias: torch.Size([2304])
blocks.0.attn.proj.weight: torch.Size([768, 768])
blocks.0.attn.proj.bias: torch.Size([768])
blocks.0.ls1.gamma: torch.Size([768])
blocks.0.norm2.weight: torch.Size([768])
blocks.0.norm2.bias: torch.Size([768])
blocks.0.mlp.fc1.weight: torch.Size([3072, 768])
blocks.0.mlp.fc1.bias: torch.Size([3072])
blocks.0.mlp.fc2.weight: torch.Size([768, 3072])
blocks.0.mlp.fc2.bias: torch.Size([768])
blocks.0.ls2.gamma: torch.Size([768])
blocks.1.norm1.weight: torch.Size([768])
blocks.1.norm1.bias: torch.Size([768])
blocks.1.attn.qkv.weight: torch.Size([2304, 768])
blocks.1.attn.qkv.bias: torch.Size([2304])
blocks.1.attn.proj.weight: torch.Size([768, 768])
blocks.1.attn.proj.bias: torch.Size([768])
blocks.1.ls1.gamma: torch.Size([768])
blocks.1.norm2.weight: torch.Size([768])
blocks.1.norm2.bias: torch.Size([768])
blocks.1.mlp.fc1.weight: torch.Size([3072, 768])
blocks.1.mlp.fc1.bias: torch.Size([3072])
blocks.1.mlp.fc2.weight: torch.Size([768, 3072])
blocks.1.mlp.fc2.bias: torch.Size([768])
blocks.1.ls2.gamma: torch.Size([768])
blocks.2.norm1.weight: torch.Size([768])
blocks.2.norm1.bias: torch.Size([768])
blocks.2.attn.qkv.weight: torch.Size([2304, 768])
blocks.2.attn.qkv.bias: torch.Size([2304])
blocks.2.attn.proj.weight: torch.Size([768, 768])
blocks.2.attn.proj.bias: torch.Size([768])
blocks.2.ls1.gamma: torch.Size([768])
blocks.2.norm2.weight: torch.Size([768])
blocks.2.norm2.bias: torch.Size([768])
blocks.2.mlp.fc1.weight: torch.Size([3072, 768])
blocks.2.mlp.fc1.bias: torch.Size([3072])
blocks.2.mlp.fc2.weight: torch.Size([768, 3072])
blocks.2.mlp.fc2.bias: torch.Size([768])
blocks.2.ls2.gamma: torch.Size([768])
blocks.3.norm1.weight: torch.Size([768])
blocks.3.norm1.bias: torch.Size([768])
blocks.3.attn.qkv.weight: torch.Size([2304, 768])
blocks.3.attn.qkv.bias: torch.Size([2304])
blocks.3.attn.proj.weight: torch.Size([768, 768])
blocks.3.attn.proj.bias: torch.Size([768])
blocks.3.ls1.gamma: torch.Size([768])
blocks.3.norm2.weight: torch.Size([768])
blocks.3.norm2.bias: torch.Size([768])
blocks.3.mlp.fc1.weight: torch.Size([3072, 768])
blocks.3.mlp.fc1.bias: torch.Size([3072])
blocks.3.mlp.fc2.weight: torch.Size([768, 3072])
blocks.3.mlp.fc2.bias: torch.Size([768])
blocks.3.ls2.gamma: torch.Size([768])
blocks.4.norm1.weight: torch.Size([768])
blocks.4.norm1.bias: torch.Size([768])
blocks.4.attn.qkv.weight: torch.Size([2304, 768])
blocks.4.attn.qkv.bias: torch.Size([2304])
blocks.4.attn.proj.weight: torch.Size([768, 768])
blocks.4.attn.proj.bias: torch.Size([768])
blocks.4.ls1.gamma: torch.Size([768])
blocks.4.norm2.weight: torch.Size([768])
blocks.4.norm2.bias: torch.Size([768])
blocks.4.mlp.fc1.weight: torch.Size([3072, 768])
blocks.4.mlp.fc1.bias: torch.Size([3072])
blocks.4.mlp.fc2.weight: torch.Size([768, 3072])
blocks.4.mlp.fc2.bias: torch.Size([768])
blocks.4.ls2.gamma: torch.Size([768])
blocks.5.norm1.weight: torch.Size([768])
blocks.5.norm1.bias: torch.Size([768])
blocks.5.attn.qkv.weight: torch.Size([2304, 768])
blocks.5.attn.qkv.bias: torch.Size([2304])
blocks.5.attn.proj.weight: torch.Size([768, 768])
blocks.5.attn.proj.bias: torch.Size([768])
blocks.5.ls1.gamma: torch.Size([768])
blocks.5.norm2.weight: torch.Size([768])
blocks.5.norm2.bias: torch.Size([768])
blocks.5.mlp.fc1.weight: torch.Size([3072, 768])
blocks.5.mlp.fc1.bias: torch.Size([3072])
blocks.5.mlp.fc2.weight: torch.Size([768, 3072])
blocks.5.mlp.fc2.bias: torch.Size([768])
blocks.5.ls2.gamma: torch.Size([768])
blocks.6.norm1.weight: torch.Size([768])
blocks.6.norm1.bias: torch.Size([768])
blocks.6.attn.qkv.weight: torch.Size([2304, 768])
blocks.6.attn.qkv.bias: torch.Size([2304])
blocks.6.attn.proj.weight: torch.Size([768, 768])
blocks.6.attn.proj.bias: torch.Size([768])
blocks.6.ls1.gamma: torch.Size([768])
blocks.6.norm2.weight: torch.Size([768])
blocks.6.norm2.bias: torch.Size([768])
blocks.6.mlp.fc1.weight: torch.Size([3072, 768])
blocks.6.mlp.fc1.bias: torch.Size([3072])
blocks.6.mlp.fc2.weight: torch.Size([768, 3072])
blocks.6.mlp.fc2.bias: torch.Size([768])
blocks.6.ls2.gamma: torch.Size([768])
blocks.7.norm1.weight: torch.Size([768])
blocks.7.norm1.bias: torch.Size([768])
blocks.7.attn.qkv.weight: torch.Size([2304, 768])
blocks.7.attn.qkv.bias: torch.Size([2304])
blocks.7.attn.proj.weight: torch.Size([768, 768])
blocks.7.attn.proj.bias: torch.Size([768])
blocks.7.ls1.gamma: torch.Size([768])
blocks.7.norm2.weight: torch.Size([768])
blocks.7.norm2.bias: torch.Size([768])
blocks.7.mlp.fc1.weight: torch.Size([3072, 768])
blocks.7.mlp.fc1.bias: torch.Size([3072])
blocks.7.mlp.fc2.weight: torch.Size([768, 3072])
blocks.7.mlp.fc2.bias: torch.Size([768])
blocks.7.ls2.gamma: torch.Size([768])
blocks.8.norm1.weight: torch.Size([768])
blocks.8.norm1.bias: torch.Size([768])
blocks.8.attn.qkv.weight: torch.Size([2304, 768])
blocks.8.attn.qkv.bias: torch.Size([2304])
blocks.8.attn.proj.weight: torch.Size([768, 768])
blocks.8.attn.proj.bias: torch.Size([768])
blocks.8.ls1.gamma: torch.Size([768])
blocks.8.norm2.weight: torch.Size([768])
blocks.8.norm2.bias: torch.Size([768])
blocks.8.mlp.fc1.weight: torch.Size([3072, 768])
blocks.8.mlp.fc1.bias: torch.Size([3072])
blocks.8.mlp.fc2.weight: torch.Size([768, 3072])
blocks.8.mlp.fc2.bias: torch.Size([768])
blocks.8.ls2.gamma: torch.Size([768])
blocks.9.norm1.weight: torch.Size([768])
blocks.9.norm1.bias: torch.Size([768])
blocks.9.attn.qkv.weight: torch.Size([2304, 768])
blocks.9.attn.qkv.bias: torch.Size([2304])
blocks.9.attn.proj.weight: torch.Size([768, 768])
blocks.9.attn.proj.bias: torch.Size([768])
blocks.9.ls1.gamma: torch.Size([768])
blocks.9.norm2.weight: torch.Size([768])
blocks.9.norm2.bias: torch.Size([768])
blocks.9.mlp.fc1.weight: torch.Size([3072, 768])
blocks.9.mlp.fc1.bias: torch.Size([3072])
blocks.9.mlp.fc2.weight: torch.Size([768, 3072])
blocks.9.mlp.fc2.bias: torch.Size([768])
blocks.9.ls2.gamma: torch.Size([768])
blocks.10.norm1.weight: torch.Size([768])
blocks.10.norm1.bias: torch.Size([768])
blocks.10.attn.qkv.weight: torch.Size([2304, 768])
blocks.10.attn.qkv.bias: torch.Size([2304])
blocks.10.attn.proj.weight: torch.Size([768, 768])
blocks.10.attn.proj.bias: torch.Size([768])
blocks.10.ls1.gamma: torch.Size([768])
blocks.10.norm2.weight: torch.Size([768])
blocks.10.norm2.bias: torch.Size([768])
blocks.10.mlp.fc1.weight: torch.Size([3072, 768])
blocks.10.mlp.fc1.bias: torch.Size([3072])
blocks.10.mlp.fc2.weight: torch.Size([768, 3072])
blocks.10.mlp.fc2.bias: torch.Size([768])
blocks.10.ls2.gamma: torch.Size([768])
blocks.11.norm1.weight: torch.Size([768])
blocks.11.norm1.bias: torch.Size([768])
blocks.11.attn.qkv.weight: torch.Size([2304, 768])
blocks.11.attn.qkv.bias: torch.Size([2304])
blocks.11.attn.proj.weight: torch.Size([768, 768])
blocks.11.attn.proj.bias: torch.Size([768])
blocks.11.ls1.gamma: torch.Size([768])
blocks.11.norm2.weight: torch.Size([768])
blocks.11.norm2.bias: torch.Size([768])
blocks.11.mlp.fc1.weight: torch.Size([3072, 768])
blocks.11.mlp.fc1.bias: torch.Size([3072])
blocks.11.mlp.fc2.weight: torch.Size([768, 3072])
blocks.11.mlp.fc2.bias: torch.Size([768])
blocks.11.ls2.gamma: torch.Size([768])
norm.weight: torch.Size([768])
norm.bias: torch.Size([768])
2024-11-21 01:34:03,324 torch.Size([1, 768])
2024-11-21 01:34:03,324 DinoVisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))
    (norm): Identity()
  )
  (blocks): ModuleList(
    (0-11): 12 x NestedTensorBlock(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): MemEffAttention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): LayerScale()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
      (ls2): LayerScale()
      (drop_path2): Identity()
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (head): Identity()
)
